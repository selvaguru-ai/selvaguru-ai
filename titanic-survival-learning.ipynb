{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ac7d8f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-20T04:20:24.762535Z",
     "iopub.status.busy": "2024-06-20T04:20:24.761311Z",
     "iopub.status.idle": "2024-06-20T04:20:25.750204Z",
     "shell.execute_reply": "2024-06-20T04:20:25.749128Z"
    },
    "papermill": {
     "duration": 0.997638,
     "end_time": "2024-06-20T04:20:25.752785",
     "exception": false,
     "start_time": "2024-06-20T04:20:24.755147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSelva - notes\\nonehot_encode = OneHotEncoder()\\nprint (onehot_encode)\\n\\n#one hot encoding the categorical values\\nfeature_array = onehot_encode.fit_transform(X[[\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"]]).toarray()\\n\\n#labelling the columns with the categorical features\\nfeature_labels = onehot_encode.categories_\\n#now we have to flaten the list since feature_labels has nested list in it\\nflattened_label = []\\nfor sublist in feature_labels:\\n    for items in sublist:\\n        flattened_label.append(items)\\n\\nprint (flattened_label)\\n#np.array(feature_labels).ravel()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Selva - notes\n",
    "onehot_encode = OneHotEncoder()\n",
    "print (onehot_encode)\n",
    "\n",
    "#one hot encoding the categorical values\n",
    "feature_array = onehot_encode.fit_transform(X[[\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"]]).toarray()\n",
    "\n",
    "#labelling the columns with the categorical features\n",
    "feature_labels = onehot_encode.categories_\n",
    "#now we have to flaten the list since feature_labels has nested list in it\n",
    "flattened_label = []\n",
    "for sublist in feature_labels:\n",
    "    for items in sublist:\n",
    "        flattened_label.append(items)\n",
    "\n",
    "print (flattened_label)\n",
    "#np.array(feature_labels).ravel()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a18031e",
   "metadata": {
    "papermill": {
     "duration": 0.003489,
     "end_time": "2024-06-20T04:20:25.760631",
     "exception": false,
     "start_time": "2024-06-20T04:20:25.757142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d24c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T04:20:25.769913Z",
     "iopub.status.busy": "2024-06-20T04:20:25.769436Z",
     "iopub.status.idle": "2024-06-20T04:20:25.814332Z",
     "shell.execute_reply": "2024-06-20T04:20:25.813162Z"
    },
    "papermill": {
     "duration": 0.052305,
     "end_time": "2024-06-20T04:20:25.816684",
     "exception": false,
     "start_time": "2024-06-20T04:20:25.764379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "(889, 11)\n",
      "177\n",
      "687\n",
      "0\n",
      "['Age', 'Cabin']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "print (train_data.columns)\n",
    "\n",
    "#Embarked has only 2 NaN values so removing the rows now\n",
    "train_data = train_data.dropna(subset = [\"Embarked\"])\n",
    "#Also dropping Text features since they are not useful in this classification\n",
    "#X = X.drop(columns = [\"PassengerId\", \"Name\", \"Ticket\"])\n",
    "\n",
    "#splitting the training data into Y (predicted variable) and X \n",
    "#(Independent variable - predictor of X)\n",
    "X = train_data.drop(['Survived'], axis = 1)\n",
    "Y = train_data['Survived']\n",
    "\n",
    "print (X.shape)\n",
    "\n",
    "#print (\"Independent variables(X): \", X[:4])\n",
    "#print (\"To be predicted variables(Y): \", Y[:4])\n",
    "\n",
    "# Check for NaN values in each column\n",
    "nan_columns = X.columns[X.isna().any()].tolist()\n",
    "print (X['Age'].isna().sum())\n",
    "print (X['Cabin'].isna().sum())\n",
    "print (X['Embarked'].isna().sum())\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29447e",
   "metadata": {
    "papermill": {
     "duration": 0.003577,
     "end_time": "2024-06-20T04:20:25.824043",
     "exception": false,
     "start_time": "2024-06-20T04:20:25.820466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Selection\n",
    "\n",
    "-- <font color = 'green'>Finding relevant features in the dataset X which will influence the Y value </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0118e9b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T04:20:25.833053Z",
     "iopub.status.busy": "2024-06-20T04:20:25.832660Z",
     "iopub.status.idle": "2024-06-20T04:20:25.850299Z",
     "shell.execute_reply": "2024-06-20T04:20:25.849205Z"
    },
    "papermill": {
     "duration": 0.02478,
     "end_time": "2024-06-20T04:20:25.852525",
     "exception": false,
     "start_time": "2024-06-20T04:20:25.827745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "Cabin,  [nan 'C85' 'C123' 'E46' 'G6' 'C103' 'D56' 'A6' 'C23 C25 C27' 'B78' 'D33'\n",
      " 'B30' 'C52' 'C83' 'F33' 'F G73' 'E31' 'A5' 'D10 D12' 'D26' 'C110'\n",
      " 'B58 B60' 'E101' 'F E69' 'D47' 'B86' 'F2' 'C2' 'E33' 'B19' 'A7' 'C49'\n",
      " 'F4' 'A32' 'B4' 'B80' 'A31' 'D36' 'D15' 'C93' 'C78' 'D35' 'C87' 'B77'\n",
      " 'E67' 'B94' 'C125' 'C99' 'C118' 'D7' 'A19' 'B49' 'D' 'C22 C26' 'C106'\n",
      " 'C65' 'E36' 'C54' 'B57 B59 B63 B66' 'C7' 'E34' 'C32' 'B18' 'C124' 'C91'\n",
      " 'E40' 'T' 'C128' 'D37' 'B35' 'E50' 'C82' 'B96 B98' 'E10' 'E44' 'A34'\n",
      " 'C104' 'C111' 'C92' 'E38' 'D21' 'E12' 'E63' 'A14' 'B37' 'C30' 'D20' 'B79'\n",
      " 'E25' 'D46' 'B73' 'C95' 'B38' 'B39' 'B22' 'C86' 'C70' 'A16' 'C101' 'C68'\n",
      " 'A10' 'E68' 'B41' 'A20' 'D19' 'D50' 'D9' 'A23' 'B50' 'A26' 'D48' 'E58'\n",
      " 'C126' 'B71' 'B51 B53 B55' 'D49' 'B5' 'B20' 'F G63' 'C62 C64' 'E24' 'C90'\n",
      " 'C45' 'E8' 'B101' 'D45' 'C46' 'D30' 'E121' 'D11' 'E77' 'F38' 'B3' 'D6'\n",
      " 'B82 B84' 'D17' 'A36' 'B102' 'B69' 'E49' 'C47' 'D28' 'E17' 'A24' 'C50'\n",
      " 'B42' 'C148']\n",
      "Sex:  ['male' 'female']\n",
      "Pclass:  [3 1 2]\n",
      "SibSp:  [1 0 3 4 2 5 8]\n",
      "Parch:  [0 1 2 5 3 4 6]\n",
      "0\n",
      "687\n",
      "177\n",
      "(889, 11)\n"
     ]
    }
   ],
   "source": [
    "#the dtypes gives the data types of each variable\n",
    "print (X.dtypes)\n",
    "# from the above we get name,sex, ticket, cabin and embarked as object data types.\n",
    "#It is clear that name does not need to be one hot encoded as it doesn't result in any\n",
    "#useful prediction. \n",
    "#To confirm embarked, cabin and sex lets perform a group by search to confirm if they \n",
    "#can be one hot encoded.\n",
    "\n",
    "# doing a distinct search in categorical features for one hot encoding.\n",
    "\n",
    "cabin_count = pd.unique(X['Cabin'])\n",
    "print (\"Cabin, \", X[\"Cabin\"].unique())\n",
    "#print (len(cabin_count))\n",
    "#print (len(X))\n",
    "print (\"Sex: \", X[\"Sex\"].unique())\n",
    "print (\"Pclass: \", X[\"Pclass\"].unique()) #categorical feature one hot encode pending\n",
    "print(\"SibSp: \", X[\"SibSp\"].unique()) #categorical feature one hot encode pending\n",
    "print (\"Parch: \", X[\"Parch\"].unique())\n",
    "\n",
    "\n",
    "print(X[\"Embarked\"].isna().sum())\n",
    "print (X[\"Cabin\"].isna().sum())\n",
    "print (X[\"Age\"].isna().sum())\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b68b9",
   "metadata": {
    "papermill": {
     "duration": 0.00369,
     "end_time": "2024-06-20T04:20:25.860146",
     "exception": false,
     "start_time": "2024-06-20T04:20:25.856456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### One hot encoding\n",
    "\n",
    "--<font color = 'green'> based on the above code the features Cabin, Sex and Embarked are categorical features, so lets convert them to numerical data with one hot encoding. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bea7caf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T04:20:25.869537Z",
     "iopub.status.busy": "2024-06-20T04:20:25.869143Z",
     "iopub.status.idle": "2024-06-20T04:20:27.165895Z",
     "shell.execute_reply": "2024-06-20T04:20:27.164585Z"
    },
    "papermill": {
     "duration": 1.304671,
     "end_time": "2024-06-20T04:20:27.168630",
     "exception": false,
     "start_time": "2024-06-20T04:20:25.863959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def data_preprocessing(X):\n",
    "    #Drop \n",
    "    X = X.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\"])\n",
    "    #nan_columns_infun = X.columns[X.isna().any()].tolist()\n",
    "    #print (\"Before removing NAN columns: \",nan_columns_infun)\n",
    "    \n",
    "    ## dealing with the Nan values\n",
    "    X[\"Cabin\"] = X[\"Cabin\"].fillna(\"NA\")\n",
    "    age_mean = X[\"Age\"].mean()\n",
    "    X[\"Age\"] = X[\"Age\"].fillna(age_mean)\n",
    "    \n",
    "    ## Step 2: Scale the numerical features to lie between 0 and 1\n",
    "    # I am using MinMax scaler.\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(X[[\"Age\", \"Fare\"]])\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=[\"Age\", \"Fare\"])\n",
    "    X = X.drop(columns=[\"Age\", \"Fare\"])\n",
    "    X = pd.concat([X.reset_index(drop=True), scaled_df.reset_index(drop=True)], axis=1)\n",
    "    #X = pd.concat([X,scaled_df], axis=1)\n",
    "    \n",
    "    #nan_columns_infun = X.columns[X.isna().any()].tolist()\n",
    "    #print (\"NAN columns: \",nan_columns_infun)\n",
    "    \n",
    "    ##Step 1: One hot encoding categorical features\n",
    "    onehot_encode = OneHotEncoder() #print (onehot_encode)\n",
    "    \n",
    "    feature_array = onehot_encode.fit_transform(X[[\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"]]).toarray()\n",
    "    feature_labels = onehot_encode.categories_ \n",
    "    print(feature_labels)\n",
    "    \n",
    "    #dropping the encoded features\n",
    "    X = X.drop(columns = [\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"])\n",
    "    \n",
    "    flattened_label = []\n",
    "    for sublist in feature_labels:\n",
    "        for items in sublist:\n",
    "            flattened_label.append(items)\n",
    "    \n",
    "    #print (flattened_label)\n",
    "    features = pd.DataFrame(feature_array, columns = flattened_label)\n",
    "    X = pd.concat([X,features], axis = 1)\n",
    "    nan_columns_infun = X.columns[X.isna().any()].tolist()\n",
    "    print (nan_columns_infun)\n",
    "    print (X.shape)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f018a2aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T04:20:27.178773Z",
     "iopub.status.busy": "2024-06-20T04:20:27.177716Z",
     "iopub.status.idle": "2024-06-20T04:20:27.213526Z",
     "shell.execute_reply": "2024-06-20T04:20:27.212158Z"
    },
    "papermill": {
     "duration": 0.043536,
     "end_time": "2024-06-20T04:20:27.216073",
     "exception": false,
     "start_time": "2024-06-20T04:20:27.172537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 2, 3]), array(['female', 'male'], dtype=object), array([0, 1, 2, 3, 4, 5, 8]), array([0, 1, 2, 3, 4, 5, 6]), array(['A10', 'A14', 'A16', 'A19', 'A20', 'A23', 'A24', 'A26', 'A31',\n",
      "       'A32', 'A34', 'A36', 'A5', 'A6', 'A7', 'B101', 'B102', 'B18',\n",
      "       'B19', 'B20', 'B22', 'B3', 'B30', 'B35', 'B37', 'B38', 'B39', 'B4',\n",
      "       'B41', 'B42', 'B49', 'B5', 'B50', 'B51 B53 B55', 'B57 B59 B63 B66',\n",
      "       'B58 B60', 'B69', 'B71', 'B73', 'B77', 'B78', 'B79', 'B80',\n",
      "       'B82 B84', 'B86', 'B94', 'B96 B98', 'C101', 'C103', 'C104', 'C106',\n",
      "       'C110', 'C111', 'C118', 'C123', 'C124', 'C125', 'C126', 'C128',\n",
      "       'C148', 'C2', 'C22 C26', 'C23 C25 C27', 'C30', 'C32', 'C45', 'C46',\n",
      "       'C47', 'C49', 'C50', 'C52', 'C54', 'C62 C64', 'C65', 'C68', 'C7',\n",
      "       'C70', 'C78', 'C82', 'C83', 'C85', 'C86', 'C87', 'C90', 'C91',\n",
      "       'C92', 'C93', 'C95', 'C99', 'D', 'D10 D12', 'D11', 'D15', 'D17',\n",
      "       'D19', 'D20', 'D21', 'D26', 'D28', 'D30', 'D33', 'D35', 'D36',\n",
      "       'D37', 'D45', 'D46', 'D47', 'D48', 'D49', 'D50', 'D56', 'D6', 'D7',\n",
      "       'D9', 'E10', 'E101', 'E12', 'E121', 'E17', 'E24', 'E25', 'E31',\n",
      "       'E33', 'E34', 'E36', 'E38', 'E40', 'E44', 'E46', 'E49', 'E50',\n",
      "       'E58', 'E63', 'E67', 'E68', 'E77', 'E8', 'F E69', 'F G63', 'F G73',\n",
      "       'F2', 'F33', 'F38', 'F4', 'G6', 'NA', 'T'], dtype=object), array(['C', 'Q', 'S'], dtype=object)]\n",
      "[]\n",
      "(889, 171)\n"
     ]
    }
   ],
   "source": [
    "X_new = data_preprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da09196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T04:20:27.226390Z",
     "iopub.status.busy": "2024-06-20T04:20:27.225485Z",
     "iopub.status.idle": "2024-06-20T04:20:27.252354Z",
     "shell.execute_reply": "2024-06-20T04:20:27.250952Z"
    },
    "papermill": {
     "duration": 0.034995,
     "end_time": "2024-06-20T04:20:27.255194",
     "exception": false,
     "start_time": "2024-06-20T04:20:27.220199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Age      Fare    1    2    3  female  male    0    1    2  ...   F2  \\\n",
      "0    0.271174  0.014151  0.0  0.0  1.0     0.0   1.0  0.0  1.0  0.0  ...  0.0   \n",
      "1    0.472229  0.139136  1.0  0.0  0.0     1.0   0.0  0.0  1.0  0.0  ...  0.0   \n",
      "2    0.321438  0.015469  0.0  0.0  1.0     1.0   0.0  1.0  0.0  0.0  ...  0.0   \n",
      "3    0.434531  0.103644  1.0  0.0  0.0     1.0   0.0  0.0  1.0  0.0  ...  0.0   \n",
      "4    0.434531  0.015713  0.0  0.0  1.0     0.0   1.0  1.0  0.0  0.0  ...  0.0   \n",
      "..        ...       ...  ...  ...  ...     ...   ...  ...  ...  ...  ...  ...   \n",
      "884  0.334004  0.025374  0.0  1.0  0.0     0.0   1.0  1.0  0.0  0.0  ...  0.0   \n",
      "885  0.233476  0.058556  1.0  0.0  0.0     1.0   0.0  1.0  0.0  0.0  ...  0.0   \n",
      "886  0.367204  0.045771  0.0  0.0  1.0     1.0   0.0  0.0  1.0  0.0  ...  0.0   \n",
      "887  0.321438  0.058556  1.0  0.0  0.0     0.0   1.0  1.0  0.0  0.0  ...  0.0   \n",
      "888  0.396833  0.015127  0.0  0.0  1.0     0.0   1.0  1.0  0.0  0.0  ...  0.0   \n",
      "\n",
      "     F33  F38   F4   G6   NA    T    C    Q    S  \n",
      "0    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
      "2    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "4    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "884  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n",
      "885  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "886  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n",
      "887  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
      "888  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
      "\n",
      "[889 rows x 171 columns]\n",
      "Index([   'Age',   'Fare',        1,        2,        3, 'female',   'male',\n",
      "              0,        1,        2,\n",
      "       ...\n",
      "           'F2',    'F33',    'F38',     'F4',     'G6',     'NA',      'T',\n",
      "            'C',      'Q',      'S'],\n",
      "      dtype='object', length=171)\n",
      "['Age', 'Cabin']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(type(X_new))\n",
    "#print (type(Y))\n",
    "\n",
    "print (X_new)\n",
    "print (X_new.columns)\n",
    "\n",
    "nan_columns = X.columns[X.isna().any()].tolist()\n",
    "print (nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d89588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T04:20:27.265614Z",
     "iopub.status.busy": "2024-06-20T04:20:27.265228Z",
     "iopub.status.idle": "2024-06-20T04:20:27.389030Z",
     "shell.execute_reply": "2024-06-20T04:20:27.387657Z"
    },
    "papermill": {
     "duration": 0.131885,
     "end_time": "2024-06-20T04:20:27.391603",
     "exception": false,
     "start_time": "2024-06-20T04:20:27.259718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size:  (711, 171)\n",
      "Test dataset size:  (178, 171)\n",
      "Training target size:  (711,)\n",
      "Test target size:  (178,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, test_size = 0.2)\n",
    "\n",
    "print ('Training dataset size: ',X_train.shape)\n",
    "print ('Test dataset size: ', X_test.shape)\n",
    "print ('Training target size: ', Y_train.shape)\n",
    "print ('Test target size: ', Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16b39eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T04:20:27.401771Z",
     "iopub.status.busy": "2024-06-20T04:20:27.401392Z",
     "iopub.status.idle": "2024-06-20T04:22:34.314420Z",
     "shell.execute_reply": "2024-06-20T04:22:34.313182Z"
    },
    "papermill": {
     "duration": 126.925176,
     "end_time": "2024-06-20T04:22:34.321040",
     "exception": false,
     "start_time": "2024-06-20T04:20:27.395864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7921348314606742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_randomForest = {\n",
    "    'n_estimators' : [100, 200, 300, 400],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [3, 5, 7, 9, 11, 13]\n",
    "}\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#initialize gridSearchCV\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid_randomForest, cv = 5)\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "#Fit the model to train data\n",
    "grid_search.fit (X_train, Y_train)\n",
    "#Get the best model \n",
    "best_model = grid_search.best_estimator_\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "#calculate the accuracy\n",
    "accuracy = accuracy_score (Y_test, y_pred)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 133.055574,
   "end_time": "2024-06-20T04:22:34.947303",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-20T04:20:21.891729",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
