{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c2fcdc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-17T01:36:29.815025Z",
     "iopub.status.busy": "2024-06-17T01:36:29.814626Z",
     "iopub.status.idle": "2024-06-17T01:36:30.831178Z",
     "shell.execute_reply": "2024-06-17T01:36:30.829754Z"
    },
    "papermill": {
     "duration": 1.025985,
     "end_time": "2024-06-17T01:36:30.834258",
     "exception": false,
     "start_time": "2024-06-17T01:36:29.808273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af32d7",
   "metadata": {
    "papermill": {
     "duration": 0.003968,
     "end_time": "2024-06-17T01:36:30.842909",
     "exception": false,
     "start_time": "2024-06-17T01:36:30.838941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4af877b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T01:36:30.853230Z",
     "iopub.status.busy": "2024-06-17T01:36:30.852693Z",
     "iopub.status.idle": "2024-06-17T01:36:30.901065Z",
     "shell.execute_reply": "2024-06-17T01:36:30.899454Z"
    },
    "papermill": {
     "duration": 0.056766,
     "end_time": "2024-06-17T01:36:30.903907",
     "exception": false,
     "start_time": "2024-06-17T01:36:30.847141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Independent variables(X):     PassengerId  Pclass                                               Name  \\\n",
      "0            1       3                            Braund, Mr. Owen Harris   \n",
      "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2            3       3                             Heikkinen, Miss. Laina   \n",
      "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
      "To be predicted variables(Y):  0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "print (train_data.columns)\n",
    "\n",
    "#splitting the training data into Y (predicted variable) and X \n",
    "#(Independent variable - predictor of X)\n",
    "\n",
    "X = train_data.drop(['Survived'], axis = 1)\n",
    "Y = train_data['Survived']\n",
    "\n",
    "print (\"Independent variables(X): \", X[:4])\n",
    "print (\"To be predicted variables(Y): \", Y[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b704d9",
   "metadata": {
    "papermill": {
     "duration": 0.004204,
     "end_time": "2024-06-17T01:36:30.912660",
     "exception": false,
     "start_time": "2024-06-17T01:36:30.908456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Selection\n",
    "\n",
    "-- <font color = 'green'>Finding relevant features in the dataset X which will influence the Y value </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca893b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T01:36:30.923340Z",
     "iopub.status.busy": "2024-06-17T01:36:30.922963Z",
     "iopub.status.idle": "2024-06-17T01:36:30.936407Z",
     "shell.execute_reply": "2024-06-17T01:36:30.935263Z"
    },
    "papermill": {
     "duration": 0.021818,
     "end_time": "2024-06-17T01:36:30.939057",
     "exception": false,
     "start_time": "2024-06-17T01:36:30.917239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "[nan 'C85' 'C123' 'E46' 'G6' 'C103' 'D56' 'A6' 'C23 C25 C27' 'B78' 'D33'\n",
      " 'B30' 'C52' 'B28' 'C83' 'F33' 'F G73' 'E31' 'A5' 'D10 D12' 'D26' 'C110'\n",
      " 'B58 B60' 'E101' 'F E69' 'D47' 'B86' 'F2' 'C2' 'E33' 'B19' 'A7' 'C49'\n",
      " 'F4' 'A32' 'B4' 'B80' 'A31' 'D36' 'D15' 'C93' 'C78' 'D35' 'C87' 'B77'\n",
      " 'E67' 'B94' 'C125' 'C99' 'C118' 'D7' 'A19' 'B49' 'D' 'C22 C26' 'C106'\n",
      " 'C65' 'E36' 'C54' 'B57 B59 B63 B66' 'C7' 'E34' 'C32' 'B18' 'C124' 'C91'\n",
      " 'E40' 'T' 'C128' 'D37' 'B35' 'E50' 'C82' 'B96 B98' 'E10' 'E44' 'A34'\n",
      " 'C104' 'C111' 'C92' 'E38' 'D21' 'E12' 'E63' 'A14' 'B37' 'C30' 'D20' 'B79'\n",
      " 'E25' 'D46' 'B73' 'C95' 'B38' 'B39' 'B22' 'C86' 'C70' 'A16' 'C101' 'C68'\n",
      " 'A10' 'E68' 'B41' 'A20' 'D19' 'D50' 'D9' 'A23' 'B50' 'A26' 'D48' 'E58'\n",
      " 'C126' 'B71' 'B51 B53 B55' 'D49' 'B5' 'B20' 'F G63' 'C62 C64' 'E24' 'C90'\n",
      " 'C45' 'E8' 'B101' 'D45' 'C46' 'D30' 'E121' 'D11' 'E77' 'F38' 'B3' 'D6'\n",
      " 'B82 B84' 'D17' 'A36' 'B102' 'B69' 'E49' 'C47' 'D28' 'E17' 'A24' 'C50'\n",
      " 'B42' 'C148']\n",
      "['male' 'female']\n",
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the dtypes gives the data types of each variable\n",
    "print (X.dtypes)\n",
    "# from the above we get name,sex, ticket, cabin and embarked as object data types.\n",
    "#It is clear that name does not need to be one hot encoded as it doesn't result in any\n",
    "#useful prediction. \n",
    "#To confirm embarked, cabin and sex lets perform a group by search to confirm if they \n",
    "#can be one hot encoded.\n",
    "\n",
    "# doing a distinct search in categorical features for one hot encoding.\n",
    "\n",
    "cabin_count = pd.unique(X['Cabin'])\n",
    "print (X[\"Cabin\"].unique())\n",
    "#print (len(cabin_count))\n",
    "#print (len(X))\n",
    "print (X[\"Sex\"].unique())\n",
    "\n",
    "print (X[\"Embarked\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51e431",
   "metadata": {
    "papermill": {
     "duration": 0.004334,
     "end_time": "2024-06-17T01:36:30.948081",
     "exception": false,
     "start_time": "2024-06-17T01:36:30.943747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### One hot encoding\n",
    "\n",
    "--<font color = 'green'> based on the above code the features Cabin, Sex and Embarked are categorical features, so lets convert them to numerical data with one hot encoding. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c17fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T01:36:30.958725Z",
     "iopub.status.busy": "2024-06-17T01:36:30.958373Z",
     "iopub.status.idle": "2024-06-17T01:36:32.402205Z",
     "shell.execute_reply": "2024-06-17T01:36:32.400927Z"
    },
    "papermill": {
     "duration": 1.452645,
     "end_time": "2024-06-17T01:36:32.405165",
     "exception": false,
     "start_time": "2024-06-17T01:36:30.952520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder()\n",
      "['A10', 'A14', 'A16', 'A19', 'A20', 'A23', 'A24', 'A26', 'A31', 'A32', 'A34', 'A36', 'A5', 'A6', 'A7', 'B101', 'B102', 'B18', 'B19', 'B20', 'B22', 'B28', 'B3', 'B30', 'B35', 'B37', 'B38', 'B39', 'B4', 'B41', 'B42', 'B49', 'B5', 'B50', 'B51 B53 B55', 'B57 B59 B63 B66', 'B58 B60', 'B69', 'B71', 'B73', 'B77', 'B78', 'B79', 'B80', 'B82 B84', 'B86', 'B94', 'B96 B98', 'C101', 'C103', 'C104', 'C106', 'C110', 'C111', 'C118', 'C123', 'C124', 'C125', 'C126', 'C128', 'C148', 'C2', 'C22 C26', 'C23 C25 C27', 'C30', 'C32', 'C45', 'C46', 'C47', 'C49', 'C50', 'C52', 'C54', 'C62 C64', 'C65', 'C68', 'C7', 'C70', 'C78', 'C82', 'C83', 'C85', 'C86', 'C87', 'C90', 'C91', 'C92', 'C93', 'C95', 'C99', 'D', 'D10 D12', 'D11', 'D15', 'D17', 'D19', 'D20', 'D21', 'D26', 'D28', 'D30', 'D33', 'D35', 'D36', 'D37', 'D45', 'D46', 'D47', 'D48', 'D49', 'D50', 'D56', 'D6', 'D7', 'D9', 'E10', 'E101', 'E12', 'E121', 'E17', 'E24', 'E25', 'E31', 'E33', 'E34', 'E36', 'E38', 'E40', 'E44', 'E46', 'E49', 'E50', 'E58', 'E63', 'E67', 'E68', 'E77', 'E8', 'F E69', 'F G63', 'F G73', 'F2', 'F33', 'F38', 'F4', 'G6', 'T', nan, 'female', 'male', 'C', 'Q', 'S', nan]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "onehot_encode = OneHotEncoder()\n",
    "print (onehot_encode)\n",
    "\n",
    "#one hot encoding the categorical values\n",
    "feature_array = onehot_encode.fit_transform(X[[\"Cabin\",\"Sex\",\"Embarked\"]]).toarray()\n",
    "\n",
    "#labelling the columns with the categorical features\n",
    "feature_labels = onehot_encode.categories_\n",
    "#now we have to flaten the list since feature_labels has nested list in it\n",
    "flattened_label = []\n",
    "for sublist in feature_labels:\n",
    "    for items in sublist:\n",
    "        flattened_label.append(items)\n",
    "\n",
    "print (flattened_label)\n",
    "#np.array(feature_labels).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7bd2567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T01:36:32.416596Z",
     "iopub.status.busy": "2024-06-17T01:36:32.416165Z",
     "iopub.status.idle": "2024-06-17T01:36:32.460552Z",
     "shell.execute_reply": "2024-06-17T01:36:32.459370Z"
    },
    "papermill": {
     "duration": 0.052995,
     "end_time": "2024-06-17T01:36:32.463068",
     "exception": false,
     "start_time": "2024-06-17T01:36:32.410073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A10</th>\n",
       "      <th>A14</th>\n",
       "      <th>A16</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A23</th>\n",
       "      <th>A24</th>\n",
       "      <th>A26</th>\n",
       "      <th>A31</th>\n",
       "      <th>A32</th>\n",
       "      <th>...</th>\n",
       "      <th>F4</th>\n",
       "      <th>G6</th>\n",
       "      <th>T</th>\n",
       "      <th>NaN</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A10  A14  A16  A19  A20  A23  A24  A26  A31  A32  ...   F4   G6    T  NaN  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "   female  male    C    Q    S  NaN  \n",
       "0     0.0   1.0  0.0  0.0  1.0  0.0  \n",
       "1     1.0   0.0  1.0  0.0  0.0  0.0  \n",
       "2     1.0   0.0  0.0  0.0  1.0  0.0  \n",
       "3     1.0   0.0  0.0  0.0  1.0  0.0  \n",
       "4     0.0   1.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "#converting the one hot encoded feature array to dataframe and \n",
    "#assigning feature label as the column name\n",
    "features = pd.DataFrame(feature_array, columns = flattened_label)\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbea0077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T01:36:32.475097Z",
     "iopub.status.busy": "2024-06-17T01:36:32.474673Z",
     "iopub.status.idle": "2024-06-17T01:36:32.484176Z",
     "shell.execute_reply": "2024-06-17T01:36:32.482914Z"
    },
    "papermill": {
     "duration": 0.018443,
     "end_time": "2024-06-17T01:36:32.486679",
     "exception": false,
     "start_time": "2024-06-17T01:36:32.468236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId',      'Pclass',        'Name',         'Sex',\n",
      "               'Age',       'SibSp',       'Parch',      'Ticket',\n",
      "              'Fare',       'Cabin',\n",
      "       ...\n",
      "                'F4',          'G6',           'T',           nan,\n",
      "            'female',        'male',           'C',           'Q',\n",
      "                 'S',           nan],\n",
      "      dtype='object', length=165)\n",
      "(891, 165)\n"
     ]
    }
   ],
   "source": [
    "#concatenating the new one hot encoded features to training data set\n",
    "X_new = pd.concat([X, features], axis = 1)\n",
    "print (X_new.columns)\n",
    "print (X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78e3edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T01:36:32.499221Z",
     "iopub.status.busy": "2024-06-17T01:36:32.498800Z",
     "iopub.status.idle": "2024-06-17T01:36:32.504970Z",
     "shell.execute_reply": "2024-06-17T01:36:32.503712Z"
    },
    "papermill": {
     "duration": 0.015508,
     "end_time": "2024-06-17T01:36:32.507720",
     "exception": false,
     "start_time": "2024-06-17T01:36:32.492212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.606677,
   "end_time": "2024-06-17T01:36:33.137080",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-17T01:36:26.530403",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
