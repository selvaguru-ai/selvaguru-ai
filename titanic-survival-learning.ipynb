{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003f36e1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-18T02:19:48.244778Z",
     "iopub.status.busy": "2024-06-18T02:19:48.244373Z",
     "iopub.status.idle": "2024-06-18T02:19:49.257720Z",
     "shell.execute_reply": "2024-06-18T02:19:49.256517Z"
    },
    "papermill": {
     "duration": 1.021701,
     "end_time": "2024-06-18T02:19:49.260243",
     "exception": false,
     "start_time": "2024-06-18T02:19:48.238542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSelva - notes\\nonehot_encode = OneHotEncoder()\\nprint (onehot_encode)\\n\\n#one hot encoding the categorical values\\nfeature_array = onehot_encode.fit_transform(X[[\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"]]).toarray()\\n\\n#labelling the columns with the categorical features\\nfeature_labels = onehot_encode.categories_\\n#now we have to flaten the list since feature_labels has nested list in it\\nflattened_label = []\\nfor sublist in feature_labels:\\n    for items in sublist:\\n        flattened_label.append(items)\\n\\nprint (flattened_label)\\n#np.array(feature_labels).ravel()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Selva - notes\n",
    "onehot_encode = OneHotEncoder()\n",
    "print (onehot_encode)\n",
    "\n",
    "#one hot encoding the categorical values\n",
    "feature_array = onehot_encode.fit_transform(X[[\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"]]).toarray()\n",
    "\n",
    "#labelling the columns with the categorical features\n",
    "feature_labels = onehot_encode.categories_\n",
    "#now we have to flaten the list since feature_labels has nested list in it\n",
    "flattened_label = []\n",
    "for sublist in feature_labels:\n",
    "    for items in sublist:\n",
    "        flattened_label.append(items)\n",
    "\n",
    "print (flattened_label)\n",
    "#np.array(feature_labels).ravel()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b90052",
   "metadata": {
    "papermill": {
     "duration": 0.003541,
     "end_time": "2024-06-18T02:19:49.267954",
     "exception": false,
     "start_time": "2024-06-18T02:19:49.264413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e05ee4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T02:19:49.277501Z",
     "iopub.status.busy": "2024-06-18T02:19:49.276970Z",
     "iopub.status.idle": "2024-06-18T02:19:49.324310Z",
     "shell.execute_reply": "2024-06-18T02:19:49.323125Z"
    },
    "papermill": {
     "duration": 0.055508,
     "end_time": "2024-06-18T02:19:49.327254",
     "exception": false,
     "start_time": "2024-06-18T02:19:49.271746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Independent variables(X):     PassengerId  Pclass                                               Name  \\\n",
      "0            1       3                            Braund, Mr. Owen Harris   \n",
      "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2            3       3                             Heikkinen, Miss. Laina   \n",
      "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
      "To be predicted variables(Y):  0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "print (train_data.columns)\n",
    "\n",
    "#splitting the training data into Y (predicted variable) and X \n",
    "#(Independent variable - predictor of X)\n",
    "\n",
    "X = train_data.drop(['Survived'], axis = 1)\n",
    "Y = train_data['Survived']\n",
    "\n",
    "print (\"Independent variables(X): \", X[:4])\n",
    "print (\"To be predicted variables(Y): \", Y[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b4292",
   "metadata": {
    "papermill": {
     "duration": 0.003845,
     "end_time": "2024-06-18T02:19:49.335208",
     "exception": false,
     "start_time": "2024-06-18T02:19:49.331363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Selection\n",
    "\n",
    "-- <font color = 'green'>Finding relevant features in the dataset X which will influence the Y value </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0945ec4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T02:19:49.345162Z",
     "iopub.status.busy": "2024-06-18T02:19:49.344724Z",
     "iopub.status.idle": "2024-06-18T02:19:49.364124Z",
     "shell.execute_reply": "2024-06-18T02:19:49.362898Z"
    },
    "papermill": {
     "duration": 0.027542,
     "end_time": "2024-06-18T02:19:49.366722",
     "exception": false,
     "start_time": "2024-06-18T02:19:49.339180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "Cabin,  [nan 'C85' 'C123' 'E46' 'G6' 'C103' 'D56' 'A6' 'C23 C25 C27' 'B78' 'D33'\n",
      " 'B30' 'C52' 'B28' 'C83' 'F33' 'F G73' 'E31' 'A5' 'D10 D12' 'D26' 'C110'\n",
      " 'B58 B60' 'E101' 'F E69' 'D47' 'B86' 'F2' 'C2' 'E33' 'B19' 'A7' 'C49'\n",
      " 'F4' 'A32' 'B4' 'B80' 'A31' 'D36' 'D15' 'C93' 'C78' 'D35' 'C87' 'B77'\n",
      " 'E67' 'B94' 'C125' 'C99' 'C118' 'D7' 'A19' 'B49' 'D' 'C22 C26' 'C106'\n",
      " 'C65' 'E36' 'C54' 'B57 B59 B63 B66' 'C7' 'E34' 'C32' 'B18' 'C124' 'C91'\n",
      " 'E40' 'T' 'C128' 'D37' 'B35' 'E50' 'C82' 'B96 B98' 'E10' 'E44' 'A34'\n",
      " 'C104' 'C111' 'C92' 'E38' 'D21' 'E12' 'E63' 'A14' 'B37' 'C30' 'D20' 'B79'\n",
      " 'E25' 'D46' 'B73' 'C95' 'B38' 'B39' 'B22' 'C86' 'C70' 'A16' 'C101' 'C68'\n",
      " 'A10' 'E68' 'B41' 'A20' 'D19' 'D50' 'D9' 'A23' 'B50' 'A26' 'D48' 'E58'\n",
      " 'C126' 'B71' 'B51 B53 B55' 'D49' 'B5' 'B20' 'F G63' 'C62 C64' 'E24' 'C90'\n",
      " 'C45' 'E8' 'B101' 'D45' 'C46' 'D30' 'E121' 'D11' 'E77' 'F38' 'B3' 'D6'\n",
      " 'B82 B84' 'D17' 'A36' 'B102' 'B69' 'E49' 'C47' 'D28' 'E17' 'A24' 'C50'\n",
      " 'B42' 'C148']\n",
      "Sex:  ['male' 'female']\n",
      "Pclass:  [3 1 2]\n",
      "SibSp:  [1 0 3 4 2 5 8]\n",
      "Parch:  [0 1 2 5 3 4 6]\n",
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "#the dtypes gives the data types of each variable\n",
    "print (X.dtypes)\n",
    "# from the above we get name,sex, ticket, cabin and embarked as object data types.\n",
    "#It is clear that name does not need to be one hot encoded as it doesn't result in any\n",
    "#useful prediction. \n",
    "#To confirm embarked, cabin and sex lets perform a group by search to confirm if they \n",
    "#can be one hot encoded.\n",
    "\n",
    "# doing a distinct search in categorical features for one hot encoding.\n",
    "\n",
    "cabin_count = pd.unique(X['Cabin'])\n",
    "print (\"Cabin, \", X[\"Cabin\"].unique())\n",
    "#print (len(cabin_count))\n",
    "#print (len(X))\n",
    "print (\"Sex: \", X[\"Sex\"].unique())\n",
    "print (\"Pclass: \", X[\"Pclass\"].unique()) #categorical feature one hot encode pending\n",
    "print(\"SibSp: \", X[\"SibSp\"].unique()) #categorical feature one hot encode pending\n",
    "print (\"Parch: \", X[\"Parch\"].unique())\n",
    "\n",
    "print (X[\"Embarked\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9b053a",
   "metadata": {
    "papermill": {
     "duration": 0.003952,
     "end_time": "2024-06-18T02:19:49.374886",
     "exception": false,
     "start_time": "2024-06-18T02:19:49.370934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### One hot encoding\n",
    "\n",
    "--<font color = 'green'> based on the above code the features Cabin, Sex and Embarked are categorical features, so lets convert them to numerical data with one hot encoding. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0fcefd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T02:19:49.384887Z",
     "iopub.status.busy": "2024-06-18T02:19:49.384487Z",
     "iopub.status.idle": "2024-06-18T02:19:50.748076Z",
     "shell.execute_reply": "2024-06-18T02:19:50.746878Z"
    },
    "papermill": {
     "duration": 1.372672,
     "end_time": "2024-06-18T02:19:50.751666",
     "exception": false,
     "start_time": "2024-06-18T02:19:49.378994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def data_preprocessing(X):\n",
    "    ##Step 1: One hot encoding categorical features\n",
    "    onehot_encode = OneHotEncoder() #print (onehot_encode)\n",
    "    \n",
    "    feature_array = onehot_encode.fit_transform(X[[\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"]]).toarray()\n",
    "    feature_labels = onehot_encode.categories_ #print(feature_labels)\n",
    "    \n",
    "    #dropping the encoded features\n",
    "    X = X.drop(columns = [\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"])\n",
    "    \n",
    "    flattened_label = []\n",
    "    for sublist in feature_labels:\n",
    "        for items in sublist:\n",
    "            flattened_label.append(items)\n",
    "    \n",
    "    #print (flattened_label)\n",
    "    features = pd.DataFrame(feature_array, columns = flattened_label)\n",
    "    \n",
    "    ## Step 2: Scale the numerical features to lie between 0 and 1\n",
    "    # I am using MinMax scaler.\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(X[[\"Age\", \"Fare\"]])\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=[\"Age\", \"Fare\"])\n",
    "    X = X.drop(columns=[\"Age\", \"Fare\"])\n",
    "    X = pd.concat([X,features,scaled_df], axis=1)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c163e37d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T02:19:50.762001Z",
     "iopub.status.busy": "2024-06-18T02:19:50.761639Z",
     "iopub.status.idle": "2024-06-18T02:19:50.793806Z",
     "shell.execute_reply": "2024-06-18T02:19:50.792470Z"
    },
    "papermill": {
     "duration": 0.040343,
     "end_time": "2024-06-18T02:19:50.796394",
     "exception": false,
     "start_time": "2024-06-18T02:19:50.756051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index(['PassengerId',        'Name',      'Ticket',             1,\n",
      "                   2,             3,      'female',        'male',\n",
      "                   0,             1,\n",
      "       ...\n",
      "                'F4',          'G6',           'T',           nan,\n",
      "                 'C',           'Q',           'S',           nan,\n",
      "               'Age',        'Fare'],\n",
      "      dtype='object', length=176)\n"
     ]
    }
   ],
   "source": [
    "X_new = data_preprocessing(X)\n",
    "print(type(X_new))\n",
    "print (type(Y))\n",
    "\n",
    "print (X_new.columns)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.310678,
   "end_time": "2024-06-18T02:19:51.321986",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-18T02:19:45.011308",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
